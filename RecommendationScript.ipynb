{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CodebustersRecommender():\n",
    "    \"\"\" \n",
    "    Implements a three stage recommendation system with a gradient boosting classifier, \n",
    "    a content-based recommender, and collaborative filter\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def fit(self, df, movies, df_ratings):\n",
    "        \"\"\"\n",
    "        df -> dataframe of entire movie database\n",
    "        movies -> dataframe of movies metadata\n",
    "        df_ratings -> dataframe of movies ratings\n",
    "        fits all three steps\n",
    "        \"\"\"\n",
    "        # 0) init\n",
    "        self.df = df\n",
    "        self.movies = movies\n",
    "        self.df_ratings = df_ratings\n",
    "        \n",
    "        # 1) fit gradient boosting classifier\n",
    "        print(\"fit step 1: gradient boosting classifier\")\n",
    "        self.recommendation_without_user_info(self.df)\n",
    "        \n",
    "        # 2) fit content-based recommender\n",
    "        print(\"fit step 2: content-based filter\")\n",
    "        self.content_based_recommendation(self.movies)\n",
    "        \n",
    "        # 3) fit collaborative recommender\n",
    "        print(\"fit step 3: collaborative filter\")\n",
    "        self.collaborative_recommendation(self.df, self.df_ratings)\n",
    "        \n",
    "        print(\"Fitting done\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, userID, age, gender, number_recommendations):\n",
    "        \"\"\"\n",
    "        predicts depending on quality of user profile\n",
    "        \"\"\"\n",
    "        \n",
    "        # get userID, movie name, user age, and user gender, and user profile quality\n",
    "        user_id = userID\n",
    "        number_recommendations = number_recommendations\n",
    "        name = self.get_user_movie(self.df, user_id)\n",
    "        age = age\n",
    "        gender = gender\n",
    "        \n",
    "        # user profile quality\n",
    "        user_profile_quality = self.df[self.df.userID==userID].nunique().movieID\n",
    "        \n",
    "        # 1) predict with gradient boosting classifier\n",
    "        # if no user ratings: needs  age, gender, number_recommendations\n",
    "        if np.isnan(user_profile_quality):\n",
    "            print(\"Predict with classifier without user info :\")\n",
    "            # concat user age and gender with movie information, and make predictions\n",
    "            # e.g. user age 25 and male\n",
    "            X = df[['age', 'gender', 'year', 'genre1', 'genre2', 'genre3']]\n",
    "            # set age\n",
    "            X['age'] = age\n",
    "            dummyvars = pd.get_dummies(X[['gender', 'genre1', 'genre2', 'genre3']])\n",
    "            # set gender\n",
    "            dummyvars['gender_F'] = 0\n",
    "            dummyvars['gender_M'] = 0\n",
    "            if gender=='M':\n",
    "                dummyvars['gender_M'] = 1\n",
    "            elif gender=='F':\n",
    "                dummyvars['gender_F'] = 1\n",
    "            # append the dummy variables to df\n",
    "            X = pd.concat([X[['age', 'year']], dummyvars], axis = 1).as_matrix()\n",
    "\n",
    "            # make predictions\n",
    "            y_pred = self.gbclf.predict(X=X)\n",
    "\n",
    "            # concat predictions to movie information\n",
    "            df_pred = pd.concat([df[['movieID', 'name']], pd.DataFrame(y_pred, index=df.index, columns=['pred_rating'])], axis = 1)\n",
    "            # shuffle 5 random movies with rating 1\n",
    "            df_pred = df_pred[df_pred.pred_rating==1]\n",
    "            recommendation = df_pred.drop('pred_rating', axis=1).sample(number_recommendations, random_state=10).set_index('movieID')\n",
    "\n",
    "            return recommendation\n",
    "        \n",
    "        # 2) predict with content-based recommender\n",
    "        # if <=20 user ratings: needs userID, name, number_recommendations\n",
    "        if user_profile_quality < 20:\n",
    "            print(\"Predict with content-based filter:\")\n",
    "            # get name of movie user already rated\n",
    "            name = self.get_user_movie(df=df, user_ID=user_id)\n",
    "            # Build a 1-dimensional array with movie titles\n",
    "            indices = pd.Series(self.movies.index, index=self.movies['name'])\n",
    "            # Ranks movies according to similarity to requested movie\n",
    "            idx = indices[name]\n",
    "            sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            sim_scores = sim_scores[1:(number_recommendations+1)]\n",
    "            movie_indices = [i[0] for i in sim_scores]\n",
    "            return self.movies.name.iloc[movie_indices]\n",
    "        \n",
    "        # 3) predict with collaborative recommender\n",
    "        # if >20 user ratings: needs user_id, number_recommendations\n",
    "        if user_profile_quality >= 20:\n",
    "            print(\"Predict with collaborative filter:\")\n",
    "            movies  = self.top_k_movies(self.item_similarity, user_id, number_recommendations)\n",
    "            return df.loc[movies[0]-1, 'name']\n",
    "\n",
    "    \n",
    "    def recommendation_without_user_info(self, df):\n",
    "        '''\n",
    "        function returns 5 random movies which have been recommended by a gradient boosting classifier\n",
    "        without user information\n",
    "\n",
    "        @param df: movie dataset 'allData'\n",
    "        '''\n",
    "        # fit\n",
    "        # ---------------------------------------------------\n",
    "        # User information before any movie ratings\n",
    "        X = df[['age', 'gender', 'year', 'genre1', 'genre2', 'genre3']]\n",
    "        y = df['rating'].as_matrix()\n",
    "\n",
    "        # Preprocessing\n",
    "        # One hot encoding\n",
    "        dummyvars = pd.get_dummies(X[['gender', 'genre1', 'genre2', 'genre3']])\n",
    "        # append the dummy variables to df\n",
    "        X = pd.concat([X[['age', 'year']], dummyvars], axis = 1).as_matrix()\n",
    "\n",
    "        print(\"GradientBoostingClassifier\")\n",
    "        self.gbclf = GradientBoostingClassifier(n_estimators=100)\n",
    "        self.gbclf.fit(X=X, y=y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    # find out from user input a movie that he rated\n",
    "    def get_user_movie(self, df, user_ID):\n",
    "        '''\n",
    "        returns a rated movie from userID\n",
    "\n",
    "        @param df: movie dataset 'allData'\n",
    "        @param user_id: target user_ID\n",
    "        '''\n",
    "        # return data from random sampled row of user\n",
    "        df_liked = df[df.rating==1]\n",
    "        movie = df[df['userID']==747].sample(1).name\n",
    "\n",
    "        # strip space at the end before return\n",
    "        return movie.item().rstrip()\n",
    "\n",
    "    # Function that get movie recommendations based on the cosine similarity score of movie genres\n",
    "    def content_based_recommendation(self, movies):\n",
    "        '''\n",
    "        Recommends number of similar movie based on movie title and similarity to movies in movie database\n",
    "\n",
    "        @param movies: pandas dataframe with movie dataset with columns (movieID, name, genres_concat)\n",
    "        @param name: movie title as string\n",
    "        @param number_recommendations: number of recommendations returned as integer\n",
    "        '''\n",
    "        # fit\n",
    "        # ---------------------------------------------------\n",
    "        # Preprocessing for tf-idf vectorization\n",
    "        # Strip space at the end of string\n",
    "        movies['name'] = movies['name'].str.rstrip()\n",
    "        # Concat genres into one string\n",
    "        movies['genres_concat'] = movies[['genre1', 'genre2', 'genre3']].astype(str).apply(' '.join, axis=1)\n",
    "        # Remove nans in string and strip spaces at the end\n",
    "        movies['genres_concat'] = movies['genres_concat'].str.replace('nan','').str.rstrip()\n",
    "\n",
    "        # Create tf_idf matrix sklearn TfidfVectorizer\n",
    "        tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "        tfidf_matrix = tf.fit_transform(movies['genres_concat'])\n",
    "\n",
    "        # calculate similarity matrix with cosine distance of tf_idf values\n",
    "        self.cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "    def fast_similarity(self, m_ratings, kind='user', epsilon=1e-9):\n",
    "        '''\n",
    "        compute the similarity\n",
    "        '''\n",
    "        # epsilon -> small number for handling dived-by-zero errors\n",
    "        if kind == 'user':\n",
    "            sim = m_ratings.dot(m_ratings.T) + epsilon\n",
    "        elif kind == 'item':\n",
    "            sim = m_ratings.T.dot(m_ratings) + epsilon\n",
    "        norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "        return (sim / norms / norms.T)\n",
    "\n",
    "    def top_k_movies(self, similarity, movie_idx, k=6):\n",
    "        return [np.argsort(similarity[movie_idx,:])[:-k-1:-1]]\n",
    "\n",
    "    def collaborative_recommendation(self, all_data, df_ratings):\n",
    "        '''\n",
    "        Recommends number of similar movies based on user item similarity\n",
    "\n",
    "        @param df_ratings: rating file from MovieLens dataset\n",
    "        @param userID: userID\n",
    "        @param number_recommendations: number of recommendations returned as integer\n",
    "        @param number_recommendations: number of recommendations returned\n",
    "\n",
    "        '''\n",
    "        # fit\n",
    "        # ---------------------------------------------------\n",
    "        # Below code creates two new columns for user id and movie id to facilitate the creation of the user item matrix\n",
    "        from itertools import cycle\n",
    "        n_users = df_ratings.userID.unique().shape[0]\n",
    "        n_movies = df_ratings.movieID.unique().shape[0]\n",
    "\n",
    "        l_users = cycle(list(range(n_users)))\n",
    "        l_movies = list(range(n_movies))\n",
    "        df_ratings['user_id'] = df_ratings['userID'].astype(\"int\")\n",
    "        df_ratings['movie_id'] = df_ratings['movieID'].astype(\"int\")\n",
    "        df_ratings['movieID'] = df_ratings['movieID'].astype(\"int\")\n",
    "        #df_ratings['movie_id2'] = df_ratings['movie_id'].astype(\"str\")\n",
    "        current_idm = 1\n",
    "        current_idu = 747\n",
    "        indm = 1\n",
    "        indu = 1\n",
    "        listMID = list(df_ratings[\"movieID\"])\n",
    "        for idx, row in df_ratings.iterrows():\n",
    "            new_idm = int(df_ratings.loc[idx, 'movieID'])\n",
    "            #intialize the  foudn movie id in list\n",
    "            foundm = False\n",
    "            for k in range(1465):\n",
    "                if new_idm in listMID:\n",
    "                    #get the index\n",
    "                    lind = listMID.index(new_idm)\n",
    "                    #update the movie_id\n",
    "                    df_ratings.loc[lind, 'movie_id'] = indm\n",
    "                    #now set that list item to zero\n",
    "                    listMID[lind]=0\n",
    "                    foundm = True\n",
    "                else:\n",
    "                    #break and fetch a new row\n",
    "                    break\n",
    "            #increment the indicator\n",
    "            if foundm:\n",
    "                indm+=1\n",
    "            #current_idm = new_idm\n",
    "\n",
    "            #there is a bit of logic problem here...\n",
    "            new_idu = int(df_ratings.loc[idx, 'userID'])\n",
    "            if new_idu==current_idu:\n",
    "                df_ratings.loc[idx, 'user_id'] = indu\n",
    "            else:\n",
    "                indu+=1\n",
    "                current_idu = new_idu\n",
    "                df_ratings.loc[idx, 'user_id'] = indu\n",
    "\n",
    "        ## construct a user item matrix\n",
    "        m_ratings = np.zeros((n_users, n_movies))\n",
    "        for row in df_ratings.itertuples():\n",
    "            #row[3] will be user rating row[4] user_id and row[5] movie_id  \n",
    "            m_ratings[row[4]-1, row[5]-1] = row[3]\n",
    "\n",
    "        # get item similarity matrix\n",
    "        self.item_similarity = self.fast_similarity(m_ratings, kind='item')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
